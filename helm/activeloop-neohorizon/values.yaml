## @section Global parameters
## Global Docker image parameters
## @param global.image.registry Global Docker image registry
## @param global.image.repository Global Docker image repository
## @param global.image.tag Global Docker image tag (immutable tags are recommended)
global:
  image:
    registry: quay.io
    repository: activeloopai/neohorizon-main
    tag: v0.1.12

  ## @param global.nodeSelector Global node selector for all pods
  nodeSelector: {}
  ## @param global.tolerations Global tolerations for all pods
  tolerations: []
  ## @param global.affinity Global affinity for all pods
  affinity: {}

  ## @section Global configuration parameters
  ## @param global.config.postgres_database PostgreSQL database name (default: see `postgresql.auth.database`)
  ## @param global.config.postgres_host PostgreSQL host address (default: see `postgresql.primary.persistence.host`)
  ## @param global.config.postgres_password PostgreSQL password (default: see `postgresql.auth.password`)
  ## @param global.config.postgres_port PostgreSQL port (default: see `postgresql.primary.persistence.port`)
  ## @param global.config.postgres_user PostgreSQL username (default: see `postgresql.auth.username`)
  ## @param global.config.rabbitmq_url RabbitMQ connection URL, default is generated from rabbitmq.auth.url
  ## @param global.config.api_key API key for api authentication
  ## @param global.config.gemini_api_key Gemini API key for gemini model
  ## @param global.config.openai_api_key OpenAI API key for openai model
  ## @param global.config.text_image__matrix_of_embeddings__ingestion_url Text image matrix of embeddings ingestion model URL
  ## @param global.config.text_image__matrix_of_embeddings__query_url Text image matrix of embeddings query model URL
  ## @param global.config.text_image__embedding__ingestion_url Text image embedding ingestion model URL
  ## @param global.config.text_image__embedding__query_url Text image embedding query model URL
  ## @param global.config.text__embedding__ingestion_url Text embedding ingestion model URL
  ## @param global.config.text__embedding__query_url Text embedding query model URL
  config:
    postgres_database: ""
    postgres_host: ""
    postgres_password: ""
    postgres_port: ""
    postgres_user: ""
    rabbitmq_url: ""
    api_key: ""
    gemini_api_key: ""
    openai_api_key: ""
    text_image__matrix_of_embeddings__ingestion_url: ""
    text_image__matrix_of_embeddings__query_url: ""
    text_image__embedding__ingestion_url: ""
    text_image__embedding__query_url: ""
    text__embedding__ingestion_url: ""
    text__embedding__query_url: ""

## @section Ingress parameters
## @param ingress.enabled Enable ingress record generation for the application
## @param ingress.className IngressClass that will be used to implement the Ingress
## @param ingress.annotations Additional custom annotations for the ingress record
## @param ingress.labels Additional custom labels for the ingress record
## @param ingress.host Default host for the ingress record
## @param ingress.tls Enable TLS configuration for the hostname defined at ingress.host parameter
ingress:
  enabled: false
  className: ""
  annotations: {}
  labels: {}
  host: "api.example.com"
  tls: []
  # tls:
  #   - hosts:
  #       - "api.example.com"
  #     secretName: "neohorizon-tls"

## @section API Services parameters
apis:
  ## @param apis.lightweight_service.enabled Enable lightweight service deployment
  ## @param apis.lightweight_service.replicas Number of lightweight service replicas to deploy
  ## @param apis.lightweight_service.port Port for the lightweight service
  ## @param apis.lightweight_service.annotations Annotations for the lightweight service deployment
  ## @param apis.lightweight_service.strategy.type Deployment strategy type
  ## @param apis.lightweight_service.scaling Horizontal Pod Autoscaler configuration
  ## @param apis.lightweight_service.command Override default container command
  ## @param apis.lightweight_service.args Override default container args
  ## @param apis.lightweight_service.service.type Kubernetes service type
  ## @param apis.lightweight_service.service.port Service port
  ## @param apis.lightweight_service.env Environment variables for the lightweight service
  ## @param apis.lightweight_service.envFrom Environment variables from ConfigMap/Secret
  ## @skip apis.lightweight_service.resources.requests.cpu
  ## @skip apis.lightweight_service.resources.requests.memory
  ## @skip apis.lightweight_service.resources.limits.cpu
  ## @skip apis.lightweight_service.resources.limits.memory
  ## @param apis.lightweight_service.serviceAccount.create Specifies whether a service account should be created
  ## @param apis.lightweight_service.serviceAccount.name The name of the service account to use
  ## @param apis.lightweight_service.serviceAccount.labels Additional labels for the service account
  ## @param apis.lightweight_service.serviceAccount.annotations Additional annotations for the service account
  ## @param apis.lightweight_service.enableHealthProbes Enable health probes for the lightweight service
  ## @param apis.lightweight_service.nodeSelector Node selector for lightweight service pods
  ## @param apis.lightweight_service.tolerations Tolerations for lightweight service pods
  ## @param apis.lightweight_service.affinity Affinity for lightweight service pods
  lightweight_service:
    enabled: true
    replicas: 2
    port: 8000
    annotations: {}
    strategy:
      type: RollingUpdate
    scaling: {}
      # minReplicas: 2
      # maxReplicas: 5
      # metrics:
      #   cpu: 70
      #   memory: 50
    command: []
    args: []
    service:
      type: ClusterIP
      port: 80
    env: {}
    envFrom: []
    resources:
      requests:
        cpu: "1"
        memory: "1Gi"
      limits:
        cpu: "2"
        memory: "2Gi"
    serviceAccount:
      create: false
      name: ""
      labels: {}
      annotations: {}
    enableHealthProbes: true
    nodeSelector: {}
    tolerations: []
    affinity: {}

  ## @param apis.files_service.enabled Enable files service deployment
  ## @param apis.files_service.replicas Number of files service replicas to deploy
  ## @param apis.files_service.port Port for the files service
  ## @param apis.files_service.strategy.type Deployment strategy type
  ## @param apis.files_service.scaling Horizontal Pod Autoscaler configuration
  ## @param apis.files_service.image.repository Docker image repository for files service
  ## @param apis.files_service.command Override default container command
  ## @param apis.files_service.args Override default container args
  ## @param apis.files_service.service.type Kubernetes service type
  ## @param apis.files_service.service.port Service port
  ## @param apis.files_service.env Environment variables for the files service
  ## @param apis.files_service.envFrom Environment variables from ConfigMap/Secret
  ## @skip apis.files_service.resources.requests.cpu
  ## @skip apis.files_service.resources.requests.memory
  ## @skip apis.files_service.resources.limits.cpu
  ## @skip apis.files_service.resources.limits.memory
  ## @param apis.files_service.serviceAccount.create Specifies whether a service account should be created
  ## @param apis.files_service.serviceAccount.name The name of the service account to use
  ## @param apis.files_service.serviceAccount.labels Additional labels for the service account
  ## @param apis.files_service.serviceAccount.annotations Additional annotations for the service account
  ## @param apis.files_service.enableHealthProbes Enable health probes for the files service
  ## @param apis.files_service.nodeSelector Node selector for files service pods
  ## @param apis.files_service.tolerations Tolerations for files service pods
  ## @param apis.files_service.affinity Affinity for files service pods
  files_service:
    enabled: true
    replicas: 3
    port: 8000
    strategy:
      type: RollingUpdate
    scaling: {}
      # minReplicas: 3
      # maxReplicas: 6
      # metrics:
      #   cpu: 80
      #   memory: 80
    image:
      repository: activeloopai/neohorizon-files
    command: []
    args: []
    service:
      type: ClusterIP
      port: 80
    env: {}
    envFrom: []
    resources:
      requests:
        cpu: "2"
        memory: 4Gi
      limits:
        cpu: "3"
        memory: 8Gi
    serviceAccount:
      create: false
      name: ""
      labels: {}
      annotations: {}
    enableHealthProbes: true
    nodeSelector: {}
    tolerations: []
    affinity: {}

## @section Workers parameters
workers:
  ## @param workers.vector_search_worker.enabled Enable vector search worker deployment
  ## @param workers.vector_search_worker.replicas Number of vector search worker replicas to deploy
  ## @param workers.vector_search_worker.annotations Annotations for the vector search worker deployment
  ## @param workers.vector_search_worker.strategy.type Deployment strategy type
  ## @param workers.vector_search_worker.scaling Horizontal Pod Autoscaler configuration
  ## @param workers.vector_search_worker.env Environment variables for the vector search worker
  ## @param workers.vector_search_worker.envFrom Environment variables from ConfigMap/Secret
  ## @skip workers.vector_search_worker.resources.requests.cpu
  ## @skip workers.vector_search_worker.resources.requests.memory
  ## @skip workers.vector_search_worker.resources.limits.cpu
  ## @skip workers.vector_search_worker.resources.limits.memory
  ## @param workers.vector_search_worker.serviceAccount.create Specifies whether a service account should be created
  ## @param workers.vector_search_worker.serviceAccount.name The name of the service account to use
  ## @param workers.vector_search_worker.serviceAccount.labels Additional labels for the service account
  ## @param workers.vector_search_worker.serviceAccount.annotations Additional annotations for the service account
  ## @param workers.vector_search_worker.enableHealthProbes Enable health probes for the vector search worker
  ## @param workers.vector_search_worker.nodeSelector Node selector for vector search worker pods
  ## @param workers.vector_search_worker.tolerations Tolerations for vector search worker pods
  ## @param workers.vector_search_worker.affinity Affinity for vector search worker pods
  vector_search_worker:
    enabled: true
    replicas: 2
    annotations: {}
    strategy:
      type: RollingUpdate
    scaling: {}
      # minReplicas: 1
      # maxReplicas: 5
      # metrics:
      #   cpu: 70
      #   memory: 70
    env: {}
    envFrom: []
    resources:
      requests:
        cpu: "12"
        memory: 24Gi
      limits:
        cpu: "15"
        memory: 30Gi
    serviceAccount:
      create: false
      name: ""
      labels: {}
      annotations: {}
    enableHealthProbes: true
    nodeSelector: {}
    tolerations: []
    affinity: {}

  ## @param workers.file_processor_worker.enabled Enable file processor worker deployment
  ## @param workers.file_processor_worker.replicas Number of file processor worker replicas to deploy
  ## @param workers.file_processor_worker.annotations Annotations for the file processor worker deployment
  ## @param workers.file_processor_worker.strategy.type Deployment strategy type
  ## @param workers.file_processor_worker.scaling Horizontal Pod Autoscaler configuration
  ## @param workers.file_processor_worker.env Environment variables for the file processor worker
  ## @param workers.file_processor_worker.envFrom Environment variables from ConfigMap/Secret
  ## @skip workers.file_processor_worker.resources.requests.cpu
  ## @skip workers.file_processor_worker.resources.requests.memory
  ## @skip workers.file_processor_worker.resources.limits.cpu
  ## @skip workers.file_processor_worker.resources.limits.memory
  ## @param workers.file_processor_worker.serviceAccount.create Specifies whether a service account should be created
  ## @param workers.file_processor_worker.serviceAccount.name The name of the service account to use
  ## @param workers.file_processor_worker.serviceAccount.labels Additional labels for the service account
  ## @param workers.file_processor_worker.serviceAccount.annotations Additional annotations for the service account
  ## @param workers.file_processor_worker.enableHealthProbes Enable health probes for the file processor worker
  ## @param workers.file_processor_worker.nodeSelector Node selector for file processor worker pods
  ## @param workers.file_processor_worker.tolerations Tolerations for file processor worker pods
  ## @param workers.file_processor_worker.affinity Affinity for file processor worker pods
  file_processor_worker:
    enabled: true
    replicas: 1
    annotations: {}
    strategy:
      type: RollingUpdate
    scaling: {}
      # minReplicas: 1
      # maxReplicas: 5
      # metrics:
      #   cpu: 70
      #   memory: 70
    env: {}
    envFrom: []
    resources:
      requests:
        cpu: "4"
        memory: 8Gi
      limits:
        cpu: "8"
        memory: 15Gi
    serviceAccount:
      create: false
      name: ""
      labels: {}
      annotations: {}
    enableHealthProbes: true
    nodeSelector: {}
    tolerations: []
    affinity: {}

  ## @param workers.embedding_worker.enabled Enable embedding worker deployment
  ## @param workers.embedding_worker.replicas Number of embedding worker replicas to deploy
  ## @param workers.embedding_worker.annotations Annotations for the embedding worker deployment
  ## @param workers.embedding_worker.strategy.type Deployment strategy type
  ## @param workers.embedding_worker.scaling Horizontal Pod Autoscaler configuration
  ## @param workers.embedding_worker.env Environment variables for the embedding worker
  ## @param workers.embedding_worker.envFrom Environment variables from ConfigMap/Secret
  ## @skip workers.embedding_worker.resources.requests.cpu
  ## @skip workers.embedding_worker.resources.requests.memory
  ## @skip workers.embedding_worker.resources.limits.cpu
  ## @skip workers.embedding_worker.resources.limits.memory
  ## @param workers.embedding_worker.serviceAccount.create Specifies whether a service account should be created
  ## @param workers.embedding_worker.serviceAccount.name The name of the service account to use
  ## @param workers.embedding_worker.serviceAccount.labels Additional labels for the service account
  ## @param workers.embedding_worker.serviceAccount.annotations Additional annotations for the service account
  ## @param workers.embedding_worker.enableHealthProbes Enable health probes for the embedding worker
  ## @param workers.embedding_worker.nodeSelector Node selector for embedding worker pods
  ## @param workers.embedding_worker.tolerations Tolerations for embedding worker pods
  ## @param workers.embedding_worker.affinity Affinity for embedding worker pods
  embedding_worker:
    enabled: true
    replicas: 1
    annotations: {}
    strategy:
      type: RollingUpdate
    scaling: {}
      # minReplicas: 1
      # maxReplicas: 5
      # metrics:
      #   cpu: 70
      #   memory: 70
    env: {}
    envFrom: []
    resources:
      requests:
        cpu: "4"
        memory: 8Gi
      limits:
        cpu: "8"
        memory: 15Gi
    serviceAccount:
      create: false
      name: ""
      labels: {}
      annotations: {}
    enableHealthProbes: true
    nodeSelector: {}
    tolerations: []
    affinity: {}

  ## @param workers.summary_generation_worker.enabled Enable summary generation worker deployment
  ## @param workers.summary_generation_worker.replicas Number of summary generation worker replicas to deploy
  ## @param workers.summary_generation_worker.annotations Annotations for the summary generation worker deployment
  ## @param workers.summary_generation_worker.strategy.type Deployment strategy type
  ## @param workers.summary_generation_worker.scaling Horizontal Pod Autoscaler configuration
  ## @param workers.summary_generation_worker.env Environment variables for the summary generation worker
  ## @param workers.summary_generation_worker.envFrom Environment variables from ConfigMap/Secret
  ## @skip workers.summary_generation_worker.resources.requests.cpu
  ## @skip workers.summary_generation_worker.resources.requests.memory
  ## @skip workers.summary_generation_worker.resources.limits.cpu
  ## @skip workers.summary_generation_worker.resources.limits.memory
  ## @param workers.summary_generation_worker.serviceAccount.create Specifies whether a service account should be created
  ## @param workers.summary_generation_worker.serviceAccount.name The name of the service account to use
  ## @param workers.summary_generation_worker.serviceAccount.labels Additional labels for the service account
  ## @param workers.summary_generation_worker.serviceAccount.annotations Additional annotations for the service account
  ## @param workers.summary_generation_worker.enableHealthProbes Enable health probes for the summary generation worker
  ## @param workers.summary_generation_worker.nodeSelector Node selector for summary generation worker pods
  ## @param workers.summary_generation_worker.tolerations Tolerations for summary generation worker pods
  ## @param workers.summary_generation_worker.affinity Affinity for summary generation worker pods
  summary_generation_worker:
    enabled: true
    replicas: 1
    annotations: {}
    strategy:
      type: RollingUpdate
    scaling: {}
      # minReplicas: 1
      # maxReplicas: 5
      # metrics:
      #   cpu: 70
      #   memory: 70
    env: {}
    envFrom: []
    resources:
      requests:
        cpu: "4"
        memory: 8Gi
      limits:
        cpu: "8"
        memory: 15Gi
    serviceAccount:
      create: false
      name: ""
      labels: {}
      annotations: {}
    enableHealthProbes: true
    nodeSelector: {}
    tolerations: []
    affinity: {}

## @section Models parameters
models:
  ## @param models.visual_model.enabled Enable visual model deployment
  ## @param models.visual_model.model_name Model name for the visual model
  ## @param models.visual_model.replicas Number of visual model replicas to deploy
  ## @param models.visual_model.port Port for the visual model service
  ## @param models.visual_model.strategy.type Deployment strategy type
  ## @param models.visual_model.scaling Horizontal Pod Autoscaler configuration
  ## @param models.visual_model.image.repository Docker image repository for visual model
  ## @param models.visual_model.service.type Kubernetes service type
  ## @param models.visual_model.service.port Service port
  ## @param models.visual_model.ingress.enabled Enable ingress record generation for visual model
  ## @param models.visual_model.ingress.className IngressClass that will be used to implement the Ingress
  ## @param models.visual_model.ingress.annotations Additional custom annotations for the ingress record
  ## @param models.visual_model.ingress.host Default host for the ingress record
  ## @skip models.visual_model.ingress.paths
  ## @param models.visual_model.ingress.tls Enable TLS configuration for the hostname
  ## @param models.visual_model.env Environment variables for the visual model
  ## @param models.visual_model.envFrom Environment variables from ConfigMap/Secret
  ## @skip models.visual_model.resources.requests.cpu
  ## @skip models.visual_model.resources.requests.memory
  ## @skip models.visual_model.resources.requests.nvidia.com/gpu
  ## @skip models.visual_model.resources.limits.cpu
  ## @skip models.visual_model.resources.limits.memory
  ## @skip models.visual_model.resources.limits.nvidia.com/gpu
  ## @param models.visual_model.serviceAccount.create Specifies whether a service account should be created
  ## @param models.visual_model.serviceAccount.name The name of the service account to use
  ## @param models.visual_model.serviceAccount.labels Additional labels for the service account
  ## @param models.visual_model.serviceAccount.annotations Additional annotations for the service account
  ## @param models.visual_model.enableHealthProbes Enable health probes for the visual model
  ## @param models.visual_model.nodeSelector Node selector for visual model pods
  ## @param models.visual_model.tolerations Tolerations for visual model pods
  ## @param models.visual_model.affinity Affinity for visual model pods
  visual_model:
    enabled: true
    model_name: "colnomic"
    replicas: 1
    port: 8000
    strategy:
      type: RollingUpdate
    scaling: {}
      # minReplicas: 1
      # maxReplicas: 5
      # metrics:
      #   cpu: 70
      #   memory: 70
    image:
      repository: activeloopai/models-triton
    service:
      type: ClusterIP
      port: 80
    ingress:
      enabled: false
      className: ""
      annotations: {}
      host: "api.example.com"
      paths:
        - path: /
          pathType: Prefix
      tls: []
    env: {}
    envFrom: []
    resources:
      requests:
        cpu: "1"
        memory: 8Gi
        nvidia.com/gpu: "1"
      limits:
        cpu: "2"
        memory: 16Gi
        nvidia.com/gpu: "1"
    serviceAccount:
      create: false
      name: ""
      labels: {}
      annotations: {}
    enableHealthProbes: false
    nodeSelector: {}
    tolerations: []
    affinity: {}

  ## @param models.text_model.enabled Enable embedding model deployment
  ## @param models.text_model.model_name Model name for the embedding model
  ## @param models.text_model.replicas Number of embedding model replicas to deploy
  ## @param models.text_model.port Port for the embedding model service
  ## @param models.text_model.strategy.type Deployment strategy type
  ## @param models.text_model.scaling Horizontal Pod Autoscaler configuration
  ## @param models.text_model.image.repository Docker image repository for embedding model
  ## @param models.text_model.service.type Kubernetes service type
  ## @param models.text_model.service.port Service port
  ## @param models.text_model.ingress.enabled Enable ingress record generation for embedding model
  ## @param models.text_model.ingress.className IngressClass that will be used to implement the Ingress
  ## @param models.text_model.ingress.annotations Additional custom annotations for the ingress record
  ## @param models.text_model.ingress.host Default host for the ingress record
  ## @skip models.text_model.ingress.paths
  ## @param models.text_model.ingress.tls Enable TLS configuration for the hostname
  ## @param models.text_model.env Environment variables for the embedding model
  ## @param models.text_model.envFrom Environment variables from ConfigMap/Secret
  ## @skip models.text_model.resources.requests.cpu
  ## @skip models.text_model.resources.requests.memory
  ## @skip models.text_model.resources.requests.nvidia.com/gpu
  ## @skip models.text_model.resources.limits.cpu
  ## @skip models.text_model.resources.limits.memory
  ## @skip models.text_model.resources.limits.nvidia.com/gpu
  ## @param models.text_model.serviceAccount.create Specifies whether a service account should be created
  ## @param models.text_model.serviceAccount.name The name of the service account to use
  ## @param models.text_model.serviceAccount.labels Additional labels for the service account
  ## @param models.text_model.serviceAccount.annotations Additional annotations for the service account
  ## @param models.text_model.enableHealthProbes Enable health probes for the embedding model
  ## @param models.text_model.nodeSelector Node selector for embedding model pods
  ## @param models.text_model.tolerations Tolerations for embedding model pods
  ## @param models.text_model.affinity Affinity for embedding model pods
  text_model:
    enabled: true
    model_name: "qwen_06B"
    replicas: 1
    port: 8000
    strategy:
      type: RollingUpdate
    scaling: {}
      # minReplicas: 1
      # maxReplicas: 5
      # metrics:
      #   cpu: 70
      #   memory: 70
    image:
      repository: activeloopai/models-triton
    service:
      type: ClusterIP
      port: 80
    ingress:
      enabled: false
      className: ""
      annotations: {}
      host: "api.example.com"
      paths:
        - path: /
          pathType: Prefix
      tls: []
    env: {}
    envFrom: []
    resources:
      requests:
        cpu: "1"
        memory: 8Gi
        nvidia.com/gpu: "1"
      limits:
        cpu: "2"
        memory: 16Gi
        nvidia.com/gpu: "1"
    serviceAccount:
      create: false
      name: ""
      labels: {}
      annotations: {}
    enableHealthProbes: false
    nodeSelector: {}
    tolerations: []
    affinity: {}

## @section PostgreSQL parameters
## @param postgresql.create Whether to create a PostgreSQL instance
## @param postgresql.auth.username PostgreSQL username
## @param postgresql.auth.password PostgreSQL password
## @param postgresql.auth.database PostgreSQL database name
## @param postgresql.primary.persistence.enabled Enable PostgreSQL persistence using PVC
## @param postgresql.primary.persistence.size PVC Storage Request for PostgreSQL data volume
## @param postgresql.resources CPU/Memory resource requests/limits for PostgreSQL
postgresql:
  create: true
  auth:
    username: "postgres"
    password: "postgres"
    database: "neohorizon"
  primary:
    persistence:
      enabled: true
      size: 10Gi
  resources: {}

## @section RabbitMQ parameters
## @param rabbitmq.create Whether to create a RabbitMQ instance
## @param rabbitmq.auth.username RabbitMQ username
## @param rabbitmq.auth.password RabbitMQ password
## @param rabbitmq.persistence.enabled Enable RabbitMQ persistence using PVC
## @param rabbitmq.persistence.size PVC Storage Request for RabbitMQ data volume
## @param rabbitmq.resources CPU/Memory resource requests/limits for RabbitMQ
rabbitmq:
  create: true
  auth:
    username: "user"
    password: "password"
  persistence:
    enabled: true
    size: 20Gi
  resources: {}
